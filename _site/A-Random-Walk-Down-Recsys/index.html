<!doctype html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="A Random Walk Down Recsys - Part 1" /><meta name="author" content="Coding Monkey" /><meta property="og:locale" content="en" /><meta name="description" content="This is a new series of blog beyond my conference paper reading blog, in which I would summarize the paper that I found interesting form Arxiv IR section and share my learnings." /><meta property="og:description" content="This is a new series of blog beyond my conference paper reading blog, in which I would summarize the paper that I found interesting form Arxiv IR section and share my learnings." /><link rel="canonical" href="https://pyemma.github.io/A-Random-Walk-Down-Recsys/" /><meta property="og:url" content="https://pyemma.github.io/A-Random-Walk-Down-Recsys/" /><meta property="og:site_name" content="Coding Monkey" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2026-01-18T00:00:00-08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="A Random Walk Down Recsys - Part 1" /><meta name="twitter:site" content="@" /><meta name="twitter:creator" content="@pyemma" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Coding Monkey","url":"https://github.com/pyemma"},"dateModified":"2026-01-18T00:00:00-08:00","datePublished":"2026-01-18T00:00:00-08:00","description":"This is a new series of blog beyond my conference paper reading blog, in which I would summarize the paper that I found interesting form Arxiv IR section and share my learnings.","headline":"A Random Walk Down Recsys - Part 1","mainEntityOfPage":{"@type":"WebPage","@id":"https://pyemma.github.io/A-Random-Walk-Down-Recsys/"},"url":"https://pyemma.github.io/A-Random-Walk-Down-Recsys/"}</script><title>A Random Walk Down Recsys - Part 1 | Coding Monkey</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Coding Monkey"><meta name="application-name" content="Coding Monkey"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="/assets/css/jekyll-theme-chirpy.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.6.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.29.0/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/glightbox@3.3.0/dist/css/glightbox.min.css"> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return 'mode'; } static get MODE_ATTR() { return 'data-mode'; } static get DARK_MODE() { return 'dark'; } static get LIGHT_MODE() { return 'light'; } static get ID() { return 'mode-toggle'; } constructor() { let self = this;this.sysDarkPrefers.addEventListener('change', () => { if (self.hasMode) { self.clearMode(); } self.notify(); }); if (!this.hasMode) { return; } if (this.isDarkMode) { this.setDark(); } else { this.setLight(); } } get sysDarkPrefers() { return window.matchMedia('(prefers-color-scheme: dark)'); } get isPreferDark() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); }get modeStatus() { if (this.hasMode) { return this.mode; } else { return this.isPreferDark ? ModeToggle.DARK_MODE : ModeToggle.LIGHT_MODE; } } setDark() { document.documentElement.setAttribute(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { document.documentElement.setAttribute(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { document.documentElement.removeAttribute(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); }notify() { window.postMessage( { direction: ModeToggle.ID, message: this.modeStatus }, '*' ); } flipMode() { if (this.hasMode) { this.clearMode(); } else { if (this.isPreferDark) { this.setLight(); } else { this.setDark(); } } this.notify(); } } const modeToggle = new ModeToggle(); </script><body><aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end"><header class="profile-wrapper"> <a href="/" id="avatar" class="rounded-circle"><img src="/assets/profile.png" width="112" height="112" alt="avatar" onerror="this.style.display='none'"></a><h1 class="site-title"> <a href="/">Coding Monkey</a>
</h1>
<p class="site-subtitle fst-italic mb-0">I’m a staff software engineer with rich experience in recommendation system and machine learning infrastructure. I spent my last 8 years in both Big-Tech (Meta &amp; LinkedIn) and startups (Aven), and I’m glad to see if my past experience and learnings could help boost your career growth <br><br> <a href="https://bit.ly/41vi77B"><strong>book a session now</strong></a></p></header><nav class="flex-column flex-grow-1 w-100 ps-0"><ul class="nav">
<li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home"></i> <span>HOME</span> </a>
</li>
<li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream"></i> <span>CATEGORIES</span> </a>
</li>
<li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags"></i> <span>TAGS</span> </a>
</li>
<li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive"></i> <span>ARCHIVES</span> </a>
</li>
<li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle"></i> <span>ABOUT</span> </a>
</li>
</ul></nav><div class="sidebar-bottom d-flex flex-wrap align-items-center w-100"> <button type="button" class="btn btn-link nav-link" aria-label="Switch Mode" id="mode-toggle"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/pyemma" aria-label="github" target="_blank" rel="noopener noreferrer"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/" aria-label="twitter" target="_blank" rel="noopener noreferrer"> <i class="fa-brands fa-x-twitter"></i> </a> <a href="javascript:location.href%20=%20'mailto:'%20+%20['pyemma1991','gmail.com'].join('@')" aria-label="email"> <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss"> <i class="fas fa-rss"></i> </a>
</div></aside><div id="main-wrapper" class="d-flex justify-content-center">
<div class="container d-flex flex-column px-xxl-5">
<header id="topbar-wrapper" aria-label="Top Bar"><div id="topbar" class="d-flex align-items-center justify-content-between px-lg-3 h-100">
<nav id="breadcrumb" aria-label="Breadcrumb"> <span> <a href="/">Home</a> </span> <span>A Random Walk Down Recsys - Part 1</span></nav><button type="button" id="sidebar-trigger" class="btn btn-link"> <i class="fas fa-bars fa-fw"></i> </button><div id="topbar-title"> Post</div>
<button type="button" id="search-trigger" class="btn btn-link"> <i class="fas fa-search fa-fw"></i> </button> <search id="search" class="align-items-center ms-3 ms-lg-0"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </search> <button type="button" class="btn btn-link text-decoration-none" id="search-cancel">Cancel</button>
</div></header><div class="row flex-grow-1">
<main aria-label="Main Content" class="col-12 col-lg-11 col-xl-9 px-md-4"><article class="px-1"><header><h1 data-toc-skip>A Random Walk Down Recsys - Part 1</h1>
<div class="post-meta text-muted"> <span> Posted <time data-ts="1768723200" data-df="ll" data-bs-toggle="tooltip" data-bs-placement="bottom"> Jan 18, 2026 </time> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="https://github.com/pyemma">Coding Monkey</a> </em> </span><div> <span class="readtime" data-bs-toggle="tooltip" data-bs-placement="bottom" title="1762 words"> <em>9 min</em> read</span>
</div>
</div>
<div style="text-align: right;"> <span> <a href="https://hitscounter.dev/api/hit?url=https%3A%2F%2Fpyemma.github.io%2F&amp;label=&amp;icon=github&amp;color=%23198754&amp;message=&amp;style=flat&amp;tz=UTC" class="popup img-link shimmer"><img src="https://hitscounter.dev/api/hit?url=https%3A%2F%2Fpyemma.github.io%2F&amp;label=&amp;icon=github&amp;color=%23198754&amp;message=&amp;style=flat&amp;tz=UTC" alt="Views" loading="lazy"></a> </span>
</div>
</div></header><div class="content">
<p>This is a new series of blog beyond my conference paper reading blog, in which I would summarize the paper that I found interesting form Arxiv IR section and share my learnings.</p>
<p>In this first blog, I would like to summarize key insights from four papers that represent the current state-of-the-art in generative recommendation: <strong>OpenOneRec</strong>, <strong>OxygenRec</strong>, <strong>Meta’s Efficient Sequential Recommendation</strong>, and <strong>Promise from Kuaishou</strong>. Each brings unique perspectives on how to effectively leverage large language models for recommendation tasks.</p>
<h2 id="openonerec-a-comprehensive-generative-recommendation-framework">
<span class="me-2">OpenOneRec: A Comprehensive Generative Recommendation Framework</span><a href="#openonerec-a-comprehensive-generative-recommendation-framework" class="anchor text-muted"><i class="fas fa-hashtag"></i></a>
</h2>
<ul>
<li><a href="https://arxiv.org/abs/2512.24762">Paper</a></li>
<li><a href="https://github.com/Kuaishou-OneRec/OpenOneRec">Code</a></li>
</ul>
<p>OpenOneRec presents a systematic approach to building LLM-based recommendation systems through careful design of semantic IDs and multi-stage training.</p>
<h3 id="semantic-id-generation-and-item-alignment">
<span class="me-2">Semantic ID Generation and Item Alignment</span><a href="#semantic-id-generation-and-item-alignment" class="anchor text-muted"><i class="fas fa-hashtag"></i></a>
</h3>
<p>The semantic ID (SID) generation pipeline is thoughtfully designed with multi-modal inputs. The model combines a 4096-dimensional text embedding with a 5×1152-dimensional visual embedding, using the classic RQ-KMeans method for encoding. This multi-modal approach ensures rich item representations that capture both textual and visual semantics.</p>
<p>During pre-training, SIDs are added as new tokens to the vocabulary. The first stage focuses exclusively on <strong>item alignment</strong>, where only the SID embeddings are updated while all other parameters remain frozen. This design choice proves critical in their ablation studies—skipping this alignment stage significantly degrades performance.</p>
<p>An interesting implementation detail is the use of special tokens <code class="language-plaintext highlighter-rouge">&lt;|item_begin|&gt;</code> and <code class="language-plaintext highlighter-rouge">&lt;|item_end|&gt;</code> to isolate semantic IDs within the sequence. This boundary demarcation could be worth experimenting with in production systems.</p>
<p>The paper also addresses a practical challenge: <strong>SID shift in transfer learning</strong>. When adapting to new domains or datasets, the distribution of semantic IDs may change. Their solution combines SID with keywords (SID + keyword), which provides robustness and maintains semantic grounding during transfer.</p>
<p>Another interesting point is regarding their implementation of RQ-KMeans, which is essentially running FAISS on a large batch of data and directly update the codebook’s parameter with the centroids computed from FAISS. I asked the author in this<a href="https://github.com/Kuaishou-OneRec/OpenOneRec/issues/13">issue</a> and get confirmed that they only trained on subset of all their inventory, which is different from what I have been doing in my experiment.</p>
<h3 id="pre-training-strategy">
<span class="me-2">Pre-training Strategy</span><a href="#pre-training-strategy" class="anchor text-muted"><i class="fas fa-hashtag"></i></a>
</h3>
<p>The pre-training follows a two-stage approach:</p>
<p><strong>Stage 1 (Item Alignment):</strong> As mentioned above, this stage focuses on aligning semantic IDs with the LLM’s representation space.</p>
<p><strong>Stage 2 (Sequence Modeling):</strong> The model is trained on the full corpus of user behavior sequences. Critically, they mix in general reasoning open source dataset to prevent catastrophic forgetting of the base LLM’s language capabilities. This ensures the model retains its linguistic understanding while learning recommendation-specific patterns.</p>
<h3 id="post-training-sft-knowledge-distillation-and-rl">
<span class="me-2">Post-training: SFT, Knowledge Distillation, and RL</span><a href="#post-training-sft-knowledge-distillation-and-rl" class="anchor text-muted"><i class="fas fa-hashtag"></i></a>
</h3>
<p>The post-training phase employs three complementary techniques:</p>
<p><strong>1. Multi-task Supervised Fine-tuning (SFT)</strong> Complex instruction-response pairs are constructed to simulate real-world recommendation scenarios and user interaction trajectories. This helps the model understand diverse recommendation contexts.</p>
<p><strong>2. On-policy Knowledge Distillation</strong> This is where things get interesting. Given a prompt, the student model generates a recommendation trajectory, and the teacher model (Qwen3 base) provides rewards using reverse KL divergence. Policy gradient methods are then used for optimization.</p>
<p>A technical challenge arises from vocabulary mismatch: the teacher model doesn’t have SID tokens in its vocabulary. The paper employs special techniques to bridge this gap, ensuring effective knowledge transfer despite the vocabulary discrepancy.</p>
<p><strong>3. Reinforcement Learning with GRPO</strong> GRPO (Group Relative Policy Optimization) addresses two key issues in SFT:</p>
<ul>
<li>
<strong>Exposure bias</strong>: The distribution mismatch between training (teacher forcing) and inference (autoregressive generation)</li>
<li>
<strong>Distinguishing near-miss vs. irrelevant recommendations</strong>: Not all incorrect recommendations are equally wrong; GRPO helps the model learn this nuance</li>
</ul>
<h3 id="feature-engineering-details">
<span class="me-2">Feature Engineering Details</span><a href="#feature-engineering-details" class="anchor text-muted"><i class="fas fa-hashtag"></i></a>
</h3>
<p>An often-overlooked detail is how user profiles are represented. OpenOneRec directly incorporates numeric features into prompts, for example: “她关注的博主类型有：[其他] 占 47.58%，[颜值] 占 16.52%”. This is also commonly known as hard prompting which is widely used in llm4rec.</p>
<h2 id="oxygenrec-jds-advanced-generative-recommendation-system">
<span class="me-2">OxygenRec: JD’s Advanced Generative Recommendation System</span><a href="#oxygenrec-jds-advanced-generative-recommendation-system" class="anchor text-muted"><i class="fas fa-hashtag"></i></a>
</h2>
<ul><li><a href="https://arxiv.org/pdf/2512.22386">Paper</a></li></ul>
<p>OxygenRec from JD shares conceptual similarities with OpenOneRec but introduces several novel techniques, particularly in semantic ID generation and training infrastructure.</p>
<p><a href="/assets/oxygenrec.png" class="popup img-link shimmer"><img src="/assets/oxygenrec.png" alt="OxygenRec Arch" loading="lazy"></a></p>
<h3 id="enhanced-semantic-id-generation">
<span class="me-2">Enhanced Semantic ID Generation</span><a href="#enhanced-semantic-id-generation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a>
</h3>
<p>The key innovation here is the use of a <strong>Q-Former architecture</strong> for multi-modal fusion. Rather than simply concatenating text and image embeddings, OxygenRec applies contrastive learning to align these modalities before RQ-KMeans encoding.</p>
<p>Their ablation study reveals important findings:</p>
<ul>
<li>Text embeddings alone perform poorly</li>
<li>Multi-modal embeddings are essential</li>
<li>
<strong>Complex fusion with contrastive learning</strong> produces the best results after collaborative filtering</li>
</ul>
<p>This suggests that simple concatenation of modalities is insufficient—proper alignment through contrastive learning is crucial for high-quality semantic IDs.</p>
<h3 id="pre-training-innovations">
<span class="me-2">Pre-training Innovations</span><a href="#pre-training-innovations" class="anchor text-muted"><i class="fas fa-hashtag"></i></a>
</h3>
<p>OxygenRec introduces two notable techniques during pre-training which mimic the <em>Thinking, Fast and Slow</em> pattern described by Daniel Kahneman.</p>
<p><strong>1. Contextual Reasoning Instructions (CRI)</strong> Inspired by Google’s work on LLM-generated user profiles, OxygenRec generates contextual reasoning instructions based on:</p>
<ul>
<li>User profile signals</li>
<li>Behavior sequences</li>
<li>Recent search history</li>
</ul>
<p>These natural language instructions are encoded through an adapter into the same embedding space as items, providing rich contextual signals.</p>
<p><strong>2. Item-Guided Retrieval (IGR)</strong> IGR adapts the GRU architecture from SIM (Search-based Interest Model), but replaces the target item with the contextual reasoning instruction. An adapter performs co-training to align item representations and CRI text representations in the same space.</p>
<p>The Q2I (Query-to-Item) alignment uses a contrastive learning approach similar to batch InfoNCE. During training, target item representations are paired with their corresponding CRI for contrastive learning, ensuring semantic consistency.</p>
<h3 id="post-training-with-soft-adaptive-policy-optimization">
<span class="me-2">Post-training with Soft Adaptive Policy Optimization</span><a href="#post-training-with-soft-adaptive-policy-optimization" class="anchor text-muted"><i class="fas fa-hashtag"></i></a>
</h3>
<p>For reinforcement learning, OxygenRec proposes <strong>Soft Adaptive Group Clip Policy Optimization (SAG-CPO)</strong>. The key insight is using a soft adaptive function to compute importance weights for positive and negative samples, which modulates the advantage estimation. This allows for more nuanced credit assignment compared to standard PPO or GRPO.</p>
<h3 id="infrastructure-optimizations">
<span class="me-2">Infrastructure Optimizations</span><a href="#infrastructure-optimizations" class="anchor text-muted"><i class="fas fa-hashtag"></i></a>
</h3>
<p>OxygenRec makes significant contributions on the systems side, which is often overlooked in research papers:</p>
<p><strong>Training Infrastructure:</strong></p>
<ul>
<li>Custom framework built on PyTorch with pipeline parallelism (PP) and tensor parallelism (TP)</li>
<li>Optimizations for distributed sparse operations</li>
<li>Claims 1.1-2.4× speedup over OSS embedding solutions (likely compared to TorchRec)</li>
<li>Techniques include HBM-Cache, multi-stage pipeline, and dual buffering</li>
</ul>
<p><strong>Attention Kernels:</strong></p>
<ul>
<li>Implementation using CUTLASS and TileLang for flexible mask configurations</li>
<li>1.7× faster than FlexAttention</li>
<li>3× faster than torch.compile</li>
</ul>
<p><strong>Inference Optimizations:</strong></p>
<ul>
<li>Custom GR (Generative Recommendation) server based on xLLM</li>
<li>
<strong>Beam Sample Kernel</strong>: Efficiently combines top-k selection with nucleus/multinomial sampling</li>
<li>
<strong>Prefix-constrained decoding</strong>: Ensures generated sequences respect structural constraints</li>
</ul>
<p>These inference techniques are particularly relevant for production deployment and could be valuable references for other generative recommendation systems.</p>
<h2 id="efficient-sequential-recommendation-for-long-term-user-interest">
<span class="me-2">Efficient Sequential Recommendation for Long-Term User Interest</span><a href="#efficient-sequential-recommendation-for-long-term-user-interest" class="anchor text-muted"><i class="fas fa-hashtag"></i></a>
</h2>
<ul><li><a href="https://arxiv.org/pdf/2601.03479">Paper</a></li></ul>
<p>This Meta paper tackles a fundamental challenge in sequential recommendation: efficiently modeling long user histories without exploding computational costs.</p>
<h3 id="core-idea-learnable-compression-tokens">
<span class="me-2">Core Idea: Learnable Compression Tokens</span><a href="#core-idea-learnable-compression-tokens" class="anchor text-muted"><i class="fas fa-hashtag"></i></a>
</h3>
<p>The key insight is elegant: use learnable tokens to compress information from each segment of the user’s history. These tokens act as “memory anchors” that summarize segments, enabling efficient reuse through KV caching during inference.</p>
<h3 id="architecture-design">
<span class="me-2">Architecture Design</span><a href="#architecture-design" class="anchor text-muted"><i class="fas fa-hashtag"></i></a>
</h3>
<p><strong>Sequence Segmentation:</strong> User sequences are divided into segments, with a learnable token appended to the end of each segment (likely placed at the end rather than the beginning to leverage attention sink phenomena).</p>
<p><strong>Attention Masking:</strong> The masking strategy is carefully designed:</p>
<ul>
<li>Each token attends only to preceding tokens within its own segment</li>
<li>Each token also attends to learnable tokens from all previous segments</li>
</ul>
<p>This creates a hierarchical attention pattern where learnable tokens act as bottlenecks for cross-segment information flow.</p>
<p><strong>Efficiency Gains:</strong> During training, the overhead is minimal. During inference, the learnable tokens (and their KV cache) can be reused directly, avoiding redundant computation over long histories.</p>
<h3 id="experimental-observations">
<span class="me-2">Experimental Observations</span><a href="#experimental-observations" class="anchor text-muted"><i class="fas fa-hashtag"></i></a>
</h3>
<p>The paper uses the MerRec dataset, which could be valuable for benchmarking. However, one finding somewhat undermines the core motivation: <strong>using a single segment performs better than multiple segments</strong>. This suggests that the compression mechanism may introduce information loss that outweighs the efficiency benefits, at least in their experimental setup.</p>
<p>This raises interesting questions about when and where such compression techniques are truly beneficial—perhaps only when sequences are extremely long or computational budgets are severely constrained.</p>
<h2 id="promise-process-reward-models-for-generative-recommendation">
<span class="me-2">Promise: Process Reward Models for Generative Recommendation</span><a href="#promise-process-reward-models-for-generative-recommendation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a>
</h2>
<ul><li><a href="https://arxiv.org/pdf/2601.04674">Paper</a></li></ul>
<p>Kuaishou’s Promise paper introduces test-time optimization for generative recommenders, addressing a critical challenge in hierarchical semantic ID generation.</p>
<h3 id="the-semantic-drift-problem">
<span class="me-2">The Semantic Drift Problem</span><a href="#the-semantic-drift-problem" class="anchor text-muted"><i class="fas fa-hashtag"></i></a>
</h3>
<p>Promise identifies a key difference between LLM text generation and generative recommendation:</p>
<p><strong>In standard LLM generation:</strong> Tokens are relatively independent; an error in one token has limited downstream impact.</p>
<p><strong>In hierarchical SID generation:</strong> Semantic IDs have hierarchical structure. If the model predicts the wrong prefix (e.g., wrong category), all subsequent tokens will be catastrophically wrong.</p>
<p>Models like OneRec train with teacher forcing (using ground-truth previous tokens), but at inference time they must use their own predictions. This train-test mismatch is a classic off-policy problem: the model never receives feedback on sequences it generates itself during training. With the hierarchical information baked in SID, this creates severe <strong>semantic drift</strong> problem during inference.</p>
<h3 id="solution-process-reward-model-prm">
<span class="me-2">Solution: Process Reward Model (PRM)</span><a href="#solution-process-reward-model-prm" class="anchor text-muted"><i class="fas fa-hashtag"></i></a>
</h3>
<p>Promise introduces a process reward model to evaluate partial sequences during generation:</p>
<p><a href="/assets/promise.png" class="popup img-link shimmer"><img src="/assets/promise.png" alt="Promise Arch" loading="lazy"></a></p>
<p><strong>Training the PRM:</strong></p>
<ul>
<li>Positive samples: Ground-truth SID token sequences</li>
<li>Negative samples: Sampled from all valid SIDs</li>
<li>Objective: InfoNCE contrastive loss</li>
</ul>
<p><strong>Architecture:</strong> The PRM design is clever and efficient:</p>
<ol>
<li>A separate embedding lookup table converts SIDs to embeddings (used as queries)</li>
<li>Reuse the GR model’s encoder output as keys/values</li>
<li>Cross-attention between SID embeddings and encoder outputs</li>
<li>Final MLP layer produces sequence scores</li>
</ol>
<p>This architecture is reminiscent of path retrieval mechanisms and enables efficient scoring without full model forward passes.</p>
<p><strong>Inference Algorithm:</strong></p>
<p><a href="/assets/promise-algo.png" class="popup img-link shimmer"><img src="/assets/promise-algo.png" alt="Promise Inference Algo" loading="lazy"></a></p>
<p>While the pseudocode appears complex, the core idea is straightforward:</p>
<ol>
<li>Perform beam search to generate candidate sequences</li>
<li>Invoke the reward model to score partial paths</li>
<li>Prune low-scoring paths</li>
<li>Continue generation with remaining high-quality candidates</li>
</ol>
<p>This is essentially test-time scaling for recommendation—using compute during inference to improve generation quality.</p>
<h3 id="new-evaluation-metric-hierarchical-recall">
<span class="me-2">New Evaluation Metric: Hierarchical Recall</span><a href="#new-evaluation-metric-hierarchical-recall" class="anchor text-muted"><i class="fas fa-hashtag"></i></a>
</h3>
<p>Promise proposes <strong>Hierarchical Recall</strong>, which measures the recall at each level of the prefix during beam search. This provides fine-grained insight into where the model succeeds or fails in the hierarchical generation process. This metric could be valuable for debugging and analyzing other hierarchical generation systems.</p>
<h2 id="key-takeaways-and-future-directions">
<span class="me-2">Key Takeaways and Future Directions</span><a href="#key-takeaways-and-future-directions" class="anchor text-muted"><i class="fas fa-hashtag"></i></a>
</h2>
<p>These four papers collectively illustrate the rapid maturation of LLM-based recommendation systems:</p>
<ol>
<li><p><strong>Semantic IDs are crucial</strong>: Multi-modal fusion with proper contrastive learning (as in OxygenRec) produces superior semantic representations compared to simple concatenation or single-modality approaches.</p></li>
<li><p><strong>Multi-stage training is standard</strong>: The pattern of item alignment → sequence pre-training → SFT → RL has emerged as a robust framework.</p></li>
<li><p><strong>Infrastructure matters</strong>: OxygenRec’s emphasis on systems optimization (training and inference) reminds us that research innovations must be complemented by engineering excellence for production deployment.</p></li>
</ol>
<blockquote class="prompt-tip"><p>If you find this post helpful, feel free to scan the QR code below to support me and treat me to a cup of coffee</p></blockquote>
<p><a href="/assets/qr%20code.png" class="popup img-link shimmer"><img src="/assets/qr%20code.png" alt="Thank You" width="300" height="300" loading="lazy"></a></p>
</div>
<div class="post-tail-wrapper text-muted">
<div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw me-1"></i> <a href="/categories/machine-learning/">Machine Learning</a>
</div>
<div class="post-tags"> <i class="fa fa-tags fa-fw me-1"></i> <a href="/tags/generative-recommender/" class="post-tag no-text-decoration">generative-recommender</a> <a href="/tags/llm4rec/" class="post-tag no-text-decoration">llm4rec</a> <a href="/tags/semantic-id/" class="post-tag no-text-decoration">semantic-id</a> <a href="/tags/user-sequence-modeling/" class="post-tag no-text-decoration">user-sequence-modeling</a> <a href="/tags/kernel/" class="post-tag no-text-decoration">kernel</a>
</div>
<div class=" post-tail-bottom d-flex justify-content-between align-items-center mt-5 pb-2 ">
<div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div>
<div class="share-wrapper d-flex align-items-center"> <span class="share-label text-muted">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=A%20Random%20Walk%20Down%20Recsys%20-%20Part%201%20-%20Coding%20Monkey&amp;url=https%3A%2F%2Fpyemma.github.io%2FA-Random-Walk-Down-Recsys%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Twitter" aria-label="Twitter"> <i class="fa-fw fa-brands fa-square-x-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=A%20Random%20Walk%20Down%20Recsys%20-%20Part%201%20-%20Coding%20Monkey&amp;u=https%3A%2F%2Fpyemma.github.io%2FA-Random-Walk-Down-Recsys%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Facebook" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fpyemma.github.io%2FA-Random-Walk-Down-Recsys%2F&amp;text=A%20Random%20Walk%20Down%20Recsys%20-%20Part%201%20-%20Coding%20Monkey" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Telegram" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <button id="copy-link" aria-label="Copy link" class="btn small" data-bs-toggle="tooltip" data-bs-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> <i class="fa-fw fas fa-link pe-none fs-6"></i> </button> </span>
</div>
</div>
</div></article></main><aside aria-label="Panel" id="panel-wrapper" class="col-xl-3 ps-2 mb-5 text-muted"><div class="access">
<section id="access-lastmod"><h2 class="panel-heading">Recently Updated</h2>
<ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2">
<li class="text-truncate lh-lg"> <a href="/A-Random-Walk-Down-Recsys/">A Random Walk Down Recsys - Part 1</a>
</li>
<li class="text-truncate lh-lg"> <a href="/FSDP2-Code-Walk/">FSDP2 Under the Hood - A Deep Dive into PyTorch's Fully Sharded Data Parallel Implementation</a>
</li>
<li class="text-truncate lh-lg"> <a href="/Recommendation-Paper-2025-Review/">My 2025 Recommendation System Paper Summary</a>
</li>
<li class="text-truncate lh-lg"> <a href="/Recsys-2025-Paper-Summary/">Recsys 2025 Paper Summary</a>
</li>
<li class="text-truncate lh-lg"> <a href="/KDD-2025-Paper-Summary/">KDD 2025 Paper Summary</a>
</li>
</ul></section><section><h2 class="panel-heading">Trending Tags</h2>
<div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/machine-learning-design/">machine learning design</a> <a class="post-tag btn btn-outline-primary" href="/tags/recommendation-system/">recommendation-system</a> <a class="post-tag btn btn-outline-primary" href="/tags/llm4rec/">llm4rec</a> <a class="post-tag btn btn-outline-primary" href="/tags/system-design/">system design</a> <a class="post-tag btn btn-outline-primary" href="/tags/user-sequence-modeling/">user-sequence-modeling</a> <a class="post-tag btn btn-outline-primary" href="/tags/distributed-system/">distributed system</a> <a class="post-tag btn btn-outline-primary" href="/tags/distributed-training/">distributed-training</a> <a class="post-tag btn btn-outline-primary" href="/tags/embeddings/">embeddings</a> <a class="post-tag btn btn-outline-primary" href="/tags/llm/">llm</a> <a class="post-tag btn btn-outline-primary" href="/tags/machine-learning-design/">machine-learning-design</a>
</div></section>
</div>
<section id="toc-wrapper" class="d-none ps-0 pe-4"><h2 class="panel-heading ps-3 mb-2">Contents</h2>
<nav id="toc"></nav></section></aside>
</div>
<div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4">
<aside id="related-posts" aria-labelledby="related-label"><h3 class="mb-4" id="related-label">Further Reading</h3>
<nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4"><article class="col"> <a href="/Recsys-2025-Paper-Summary/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1764230400" data-df="ll"> Nov 27, 2025 </time><h4 class="pt-0 my-2">Recsys 2025 Paper Summary</h4>
<div class="text-muted"><p>In this post, I would like to summary the paper from Recsys 2025 and share some of my learnings. We would cover several topics such as sequence modeling, cross domain learning as well as LLM integr...</p></div>
</div></a></article><article class="col"> <a href="/KDD-2025-Paper-Summary/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1760684400" data-df="ll"> Oct 17, 2025 </time><h4 class="pt-0 my-2">KDD 2025 Paper Summary</h4>
<div class="text-muted"><p>It has been a while since KDD 2025, finally I have had sometime to finish reading all papers that I interested in and summarize some of my learnings in this post <img class="emoji" title=":sweat_smile:" alt=":sweat_smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f605.png" height="20" width="20">. My primary focus is ...</p></div>
</div></a></article><article class="col"> <a href="/Recommendation-Paper-2025-Review/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1767340800" data-df="ll"> Jan 2, 2026 </time><h4 class="pt-0 my-2">My 2025 Recommendation System Paper Summary</h4>
<div class="text-muted"><p>In this post, I would like to share some insights from the paper I have read in year 2025 and summarize some trends over the year. The One The best work I enjoyed this year is the One-series from...</p></div>
</div></a></article></nav></aside><nav class="post-navigation d-flex justify-content-between" aria-label="Post Navigation"> <a href="/FSDP2-Code-Walk/" class="btn btn-outline-primary" aria-label="Older"><p>FSDP2 Under the Hood - A Deep Dive into PyTorch's Fully Sharded Data Parallel Implementation</p></a><div class="btn btn-outline-primary disabled" aria-label="Newer"><p>-</p></div></nav><div id="disqus_thread"><p class="text-center text-muted small">Comments powered by <a href="https://disqus.com/">Disqus</a>.</p></div>
<script type="text/javascript"> var disqus_config = function () { this.page.url = 'https://pyemma.github.io/A-Random-Walk-Down-Recsys/'; this.page.identifier = '/A-Random-Walk-Down-Recsys/'; };var disqus_observer = new IntersectionObserver( function (entries) { if (entries[0].isIntersecting) { (function () { var d = document, s = d.createElement('script'); s.src = 'https://pyemma.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); disqus_observer.disconnect(); } }, { threshold: [0] } ); disqus_observer.observe(document.getElementById('disqus_thread'));function reloadDisqus() { if (event.source === window && event.data && event.data.direction === ModeToggle.ID) {if (typeof DISQUS === 'undefined') { return; } if (document.readyState == 'complete') { DISQUS.reset({ reload: true, config: disqus_config }); } } } if (document.getElementById('mode-toggle')) { window.addEventListener('message', reloadDisqus); } </script><footer aria-label="Site Info" class=" d-flex flex-column justify-content-center text-muted flex-lg-row justify-content-lg-between align-items-lg-center pb-lg-3 "><p>© <time>2026</time> <a href="https://github.com/pyemma">Coding Monkey</a>. <span data-bs-toggle="tooltip" data-bs-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p>
<p>Using the <a data-bs-toggle="tooltip" data-bs-placement="top" title="v7.1.1" href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme for <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>.</p></footer>
</div></div>
<div id="search-result-wrapper" class="d-flex justify-content-center d-none"><div class="col-11 content">
<div id="search-hints"><section><h2 class="panel-heading">Trending Tags</h2>
<div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/machine-learning-design/">machine learning design</a> <a class="post-tag btn btn-outline-primary" href="/tags/recommendation-system/">recommendation-system</a> <a class="post-tag btn btn-outline-primary" href="/tags/llm4rec/">llm4rec</a> <a class="post-tag btn btn-outline-primary" href="/tags/system-design/">system design</a> <a class="post-tag btn btn-outline-primary" href="/tags/user-sequence-modeling/">user-sequence-modeling</a> <a class="post-tag btn btn-outline-primary" href="/tags/distributed-system/">distributed system</a> <a class="post-tag btn btn-outline-primary" href="/tags/distributed-training/">distributed-training</a> <a class="post-tag btn btn-outline-primary" href="/tags/embeddings/">embeddings</a> <a class="post-tag btn btn-outline-primary" href="/tags/llm/">llm</a> <a class="post-tag btn btn-outline-primary" href="/tags/machine-learning-design/">machine-learning-design</a>
</div></section></div>
<div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
</div></div>
</div>
<aside aria-label="Scroll to Top"> <button id="back-to-top" type="button" class="btn btn-lg btn-box-shadow"> <i class="fas fa-angle-up"></i> </button></aside>
</div><div id="mask"></div><aside id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-bs-animation="true" data-bs-autohide="false"><div class="toast-header"> <button type="button" class="btn-close ms-auto" data-bs-dismiss="toast" aria-label="Close"></button>
</div>
<div class="toast-body text-center pt-0">
<p class="px-2 mb-3">A new version of content is available.</p>
<button type="button" class="btn btn-primary" aria-label="Update"> Update </button>
</div></aside><script src="https://cdn.jsdelivr.net/combine/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.umd.min.js,npm/glightbox@3.3.0/dist/js/glightbox.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.13/dayjs.min.js,npm/dayjs@1.11.13/locale/en.js,npm/dayjs@1.11.13/plugin/relativeTime.js,npm/dayjs@1.11.13/plugin/localizedFormat.js,npm/tocbot@4.29.0/dist/tocbot.min.js"></script> <script src="/assets/js/dist/post.min.js"></script> <script src="/assets/js/data/mathjax.js"></script> <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml.js"></script> <script defer src="/app.min.js?baseurl=&amp;register=true"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-M1GM2SJR6M"></script> <script> document.addEventListener('DOMContentLoaded', function (event) { window.dataLayer = window.dataLayer || []; function gtag() { dataLayer.push(arguments); } gtag('js', new Date()); gtag('config', 'G-M1GM2SJR6M'); }); </script> <script>SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<article class="px-1 px-sm-2 px-lg-4 px-xl-0"><header><h2><a href="{url}">{title}</a></h2><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div></header><p>{snippet}</p></article>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
