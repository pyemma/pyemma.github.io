<!doctype html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="A Random Walk Down Recsys - Part 2" /><meta name="author" content="Coding Monkey" /><meta property="og:locale" content="en" /><meta name="description" content="Welcome back to the second installment of A Random Walk Down Recsys. In this post, I continue surveying interesting papers from the Arxiv IR section, covering five recent works: HyFormer, Token-level Collaborative Alignment, OneMall, a Sparse Attention approach for long-term user behaviors, and Farewell to Item IDs." /><meta property="og:description" content="Welcome back to the second installment of A Random Walk Down Recsys. In this post, I continue surveying interesting papers from the Arxiv IR section, covering five recent works: HyFormer, Token-level Collaborative Alignment, OneMall, a Sparse Attention approach for long-term user behaviors, and Farewell to Item IDs." /><link rel="canonical" href="https://pyemma.github.io/A-Random-Walk-Down-Recsys-Part-2/" /><meta property="og:url" content="https://pyemma.github.io/A-Random-Walk-Down-Recsys-Part-2/" /><meta property="og:site_name" content="Coding Monkey" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2026-02-05T00:00:00-08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="A Random Walk Down Recsys - Part 2" /><meta name="twitter:site" content="@" /><meta name="twitter:creator" content="@pyemma" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Coding Monkey","url":"https://github.com/pyemma"},"dateModified":"2026-02-05T00:00:00-08:00","datePublished":"2026-02-05T00:00:00-08:00","description":"Welcome back to the second installment of A Random Walk Down Recsys. In this post, I continue surveying interesting papers from the Arxiv IR section, covering five recent works: HyFormer, Token-level Collaborative Alignment, OneMall, a Sparse Attention approach for long-term user behaviors, and Farewell to Item IDs.","headline":"A Random Walk Down Recsys - Part 2","mainEntityOfPage":{"@type":"WebPage","@id":"https://pyemma.github.io/A-Random-Walk-Down-Recsys-Part-2/"},"url":"https://pyemma.github.io/A-Random-Walk-Down-Recsys-Part-2/"}</script><title>A Random Walk Down Recsys - Part 2 | Coding Monkey</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Coding Monkey"><meta name="application-name" content="Coding Monkey"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="/assets/css/jekyll-theme-chirpy.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.6.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.29.0/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/glightbox@3.3.0/dist/css/glightbox.min.css"> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return 'mode'; } static get MODE_ATTR() { return 'data-mode'; } static get DARK_MODE() { return 'dark'; } static get LIGHT_MODE() { return 'light'; } static get ID() { return 'mode-toggle'; } constructor() { let self = this;this.sysDarkPrefers.addEventListener('change', () => { if (self.hasMode) { self.clearMode(); } self.notify(); }); if (!this.hasMode) { return; } if (this.isDarkMode) { this.setDark(); } else { this.setLight(); } } get sysDarkPrefers() { return window.matchMedia('(prefers-color-scheme: dark)'); } get isPreferDark() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); }get modeStatus() { if (this.hasMode) { return this.mode; } else { return this.isPreferDark ? ModeToggle.DARK_MODE : ModeToggle.LIGHT_MODE; } } setDark() { document.documentElement.setAttribute(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { document.documentElement.setAttribute(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { document.documentElement.removeAttribute(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); }notify() { window.postMessage( { direction: ModeToggle.ID, message: this.modeStatus }, '*' ); } flipMode() { if (this.hasMode) { this.clearMode(); } else { if (this.isPreferDark) { this.setLight(); } else { this.setDark(); } } this.notify(); } } const modeToggle = new ModeToggle(); </script><body><aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end"><header class="profile-wrapper"> <a href="/" id="avatar" class="rounded-circle"><img src="/assets/profile.png" width="112" height="112" alt="avatar" onerror="this.style.display='none'"></a><h1 class="site-title"> <a href="/">Coding Monkey</a></h1><p class="site-subtitle fst-italic mb-0">I’m a staff software engineer with rich experience in recommendation system and machine learning infrastructure. I spent my last 8 years in both Big-Tech (Meta & LinkedIn) and startups (Aven), and I’m glad to see if my past experience and learnings could help boost your career growth <br><br> <a href="https://bit.ly/41vi77B"><strong>book a session now</strong></a></p></header><nav class="flex-column flex-grow-1 w-100 ps-0"><ul class="nav"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle"></i> <span>ABOUT</span> </a></ul></nav><div class="sidebar-bottom d-flex flex-wrap align-items-center w-100"> <button type="button" class="btn btn-link nav-link" aria-label="Switch Mode" id="mode-toggle"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/pyemma" aria-label="github" target="_blank" rel="noopener noreferrer" > <i class="fab fa-github"></i> </a> <a href="https://twitter.com/" aria-label="twitter" target="_blank" rel="noopener noreferrer" > <i class="fa-brands fa-x-twitter"></i> </a> <a href="javascript:location.href = 'mailto:' + ['pyemma1991','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></aside><div id="main-wrapper" class="d-flex justify-content-center"><div class="container d-flex flex-column px-xxl-5"><header id="topbar-wrapper" aria-label="Top Bar"><div id="topbar" class="d-flex align-items-center justify-content-between px-lg-3 h-100" ><nav id="breadcrumb" aria-label="Breadcrumb"> <span> <a href="/">Home</a> </span> <span>A Random Walk Down Recsys - Part 2</span></nav><button type="button" id="sidebar-trigger" class="btn btn-link"> <i class="fas fa-bars fa-fw"></i> </button><div id="topbar-title"> Post</div><button type="button" id="search-trigger" class="btn btn-link"> <i class="fas fa-search fa-fw"></i> </button> <search id="search" class="align-items-center ms-3 ms-lg-0"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..." > </search> <button type="button" class="btn btn-link text-decoration-none" id="search-cancel">Cancel</button></div></header><div class="row flex-grow-1"><main aria-label="Main Content" class="col-12 col-lg-11 col-xl-9 px-md-4"><article class="px-1"><header><h1 data-toc-skip>A Random Walk Down Recsys - Part 2</h1><div class="post-meta text-muted"> <span> Posted <time data-ts="1770278400" data-df="ll" data-bs-toggle="tooltip" data-bs-placement="bottom" > Feb 5, 2026 </time> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="https://github.com/pyemma">Coding Monkey</a> </em> </span><div> <span class="readtime" data-bs-toggle="tooltip" data-bs-placement="bottom" title="1626 words" > <em>9 min</em> read</span></div></div><div style="text-align: right;"> <span> <a href="https://hitscounter.dev/api/hit?url=https%3A%2F%2Fpyemma.github.io%2F&label=&icon=github&color=%23198754&message=&style=flat&tz=UTC" class="popup img-link shimmer"><img src="https://hitscounter.dev/api/hit?url=https%3A%2F%2Fpyemma.github.io%2F&label=&icon=github&color=%23198754&message=&style=flat&tz=UTC" alt="Views" loading="lazy"></a> </span></div></div></header><div class="content"><p>Welcome back to the second installment of <em>A Random Walk Down Recsys</em>. In this post, I continue surveying interesting papers from the Arxiv IR section, covering five recent works: <strong>HyFormer</strong>, <strong>Token-level Collaborative Alignment</strong>, <strong>OneMall</strong>, a <strong>Sparse Attention</strong> approach for long-term user behaviors, and <strong>Farewell to Item IDs</strong>.</p><h2 id="hyformer-hybrid-cross-attention-for-sequential-and-non-sequential-features"><span class="me-2">HyFormer: Hybrid Cross-Attention for Sequential and Non-Sequential Features</span><a href="#hyformer-hybrid-cross-attention-for-sequential-and-non-sequential-features" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><ul><li><a href="https://arxiv.org/pdf/2601.12681">Paper</a></ul><p>This paper from TikTok focuses on a practical yet under-explored problem: how to effectively perform cross-learning between sequential features (e.g., user behavior histories) and non-sequential features (e.g., user profiles, context signals).</p><p><a href="/assets/hyformer.png" class="popup img-link shimmer"><img src="/assets/hyformer.png" alt="HyFormer" loading="lazy"></a></p><h3 id="global-query-token-generation"><span class="me-2">Global Query Token Generation</span><a href="#global-query-token-generation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>The approach begins by constructing <strong>global query tokens</strong> from both feature types:</p><ul><li><strong>Non-sequential features</strong> are grouped semantically, and each group is concatenated and passed through a feed-forward network (FFN) for non-linear transformation.<li><strong>Sequential features</strong> are compressed via pooling and similarly passed through an FFN.</ul><p>This produces $(N)$ global query tokens that serve as the bridge between the two feature modalities.</p><h3 id="query-decoding-extracting-information-from-sequences"><span class="me-2">Query Decoding: Extracting Information from Sequences</span><a href="#query-decoding-extracting-information-from-sequences" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>The first key component is <strong>Query Decoding</strong>, which performs cross-attention between the global query tokens and sequential information. The KV extraction from the sequence is designed to be configurable: it can use a standard Transformer, or a dual short-sequence/long-sequence cross-attention mechanism similar to LONGER. The intuition here is akin to deep cross networks: the global query tokens iteratively extract relevant information from the sequence to form enriched representations for downstream layers.</p><h3 id="query-boosting-reintroducing-non-sequential-interactions"><span class="me-2">Query Boosting: Reintroducing Non-Sequential Interactions</span><a href="#query-boosting-reintroducing-non-sequential-interactions" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>The second component, <strong>Query Boosting</strong>, reintroduces interaction with non-sequential features. It adopts the RankMixer approach: global query tokens and non-sequential feature tokens are split along the feature dimension (similar to product quantization), then recombined. This effectively reshapes the representation from $(D \times T)$ to $(T \times D)$, enabling richer cross-feature interactions.</p><h3 id="multi-sequence-handling"><span class="me-2">Multi-Sequence Handling</span><a href="#multi-sequence-handling" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>For users with multiple behavior sequences (e.g., clicks, purchases, searches), HyFormer does not fuse sequences early. Instead, each sequence follows its own independent path and is only merged during the Query Boosting stage—a design choice that preserves sequence-specific signals while still enabling cross-sequence interaction.</p><h3 id="infrastructure-optimizations"><span class="me-2">Infrastructure Optimizations</span><a href="#infrastructure-optimizations" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>The paper also contributes on the systems side:</p><ul><li><strong>GPU-side Feature Reconstruction</strong>: Features are stored in a compressed embedding table and reconstructed on GPU using a deduplication-like mechanism, reducing memory overhead.<li><strong>Async All-Reduce</strong>: Gradient synchronization for step $(k)$ is overlapped with the forward/backward pass of step $(k+1)$, improving training throughput.</ul><h2 id="token-level-collaborative-alignment-for-llm-based-generative-recommendation"><span class="me-2">Token-level Collaborative Alignment for LLM-based Generative Recommendation</span><a href="#token-level-collaborative-alignment-for-llm-based-generative-recommendation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><ul><li><a href="https://www.arxiv.org/pdf/2601.18457">Paper</a></ul><p>This paper introduces a novel approach to inject <strong>collaborative filtering signals</strong> into the training of generative recommenders (GR). The core idea is to derive a token-level probability distribution from collaborative signals and incorporate it as a soft label during next-token prediction (NTP) training.</p><p><a href="/assets/token-level.png" class="popup img-link shimmer"><img src="/assets/token-level.png" alt="Token-level Collaborative Alignment" loading="lazy"></a></p><h3 id="collaborative-signal-computation"><span class="me-2">Collaborative Signal Computation</span><a href="#collaborative-signal-computation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Collaborative information is computed via traditional ID-based models using user and item embeddings with a scoring function (e.g., dot product). Although the paper does not elaborate, this likely requires computing scores for all user-item pairs.</p><h3 id="token-distribution-construction"><span class="me-2">Token Distribution Construction</span><a href="#token-distribution-construction" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>The process works as follows:</p><ol><li><strong>Tokenization</strong>: Item textual information is converted into token sequences using the LLM tokenizer.<li><strong>Prefix-based Item Grouping</strong>: At each decoding position, items are grouped by their shared prefix in the token sequence.<li><strong>Logit Normalization</strong>: The collaborative scores within each group are normalized.<li><strong>Cumulative Token Probability</strong>: By examining the next token at each decoding position and accumulating probabilities, a token-level distribution is derived.</ol><p>This distribution is then used as a <strong>soft label</strong> alongside the standard NTP loss during training, effectively distilling collaborative knowledge into the generative model’s token-level predictions.</p><h2 id="onemall-end-to-end-generative-recommendation-with-semantic-ids"><span class="me-2">OneMall: End-to-End Generative Recommendation with Semantic IDs</span><a href="#onemall-end-to-end-generative-recommendation-with-semantic-ids" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><ul><li><a href="https://arxiv.org/pdf/2601.21770">Paper</a></ul><p>OneMall presents a comprehensive pipeline for generative recommendation, spanning semantic ID generation, pre-training, and post-training with reinforcement learning.</p><h3 id="semantic-id-generation"><span class="me-2">Semantic ID Generation</span><a href="#semantic-id-generation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><a href="/assets/one-mall-sid.png" class="popup img-link shimmer"><img src="/assets/one-mall-sid.png" alt="OneMall SID" loading="lazy"></a></p><p>The semantic ID pipeline takes a distinctive approach:</p><ul><li><strong>Embedding Generation</strong>: I2I (item-to-item) datasets are mined to train specialized embeddings. Swing Transformer and Qwen3 are used for processing, followed by fine-tuning an LLM with InfoNCE loss to produce the final embeddings.<li><strong>Quantization with FSQ</strong>: Rather than standard RQ-KMeans, OneMall adopts <strong>Finite Scalar Quantization (FSQ)</strong> for the residual component, which significantly reduces ID conflicts—from ~36% with RQ-KMeans down to ~11% with FSQ.</ul><p>However, an interesting observation from their experiments is that this dramatic reduction in conflict rate does not translate into a proportionally significant improvement in Hit Rate. This suggests that pursuing extremely low conflict rates may yield diminishing returns.</p><h3 id="pre-training-architecture"><span class="me-2">Pre-training Architecture</span><a href="#pre-training-architecture" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><a href="/assets/one-mall-arch.png" class="popup img-link shimmer"><img src="/assets/one-mall-arch.png" alt="OneMall Arch" loading="lazy"></a></p><p>The backbone employs several noteworthy design choices:</p><ul><li><strong>Query-Former for Long Sequence Compression</strong>: Long user behavior sequences are compressed using a Query-Former mechanism, reducing computational cost while preserving essential information.<li><strong>Cross-Attention for SID Generation</strong>: Semantic IDs are generated through cross-attention, allowing the model to attend to compressed sequence representations.<li><strong>Sparse MoE</strong>: A Sparse Mixture-of-Experts layer is introduced to increase the model’s learnable parameter capacity without proportionally increasing compute.</ul><p>An interesting detail: the hidden state of the <strong>last SID token</strong> is extracted and used to compute a contrastive loss against item representations. Here, item features are also compressed through a Query-Former into a single item representation, creating an additional alignment signal between generated SIDs and item semantics.</p><h3 id="post-training-with-reinforcement-learning"><span class="me-2">Post-training with Reinforcement Learning</span><a href="#post-training-with-reinforcement-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>The post-training stage uses RL with the following setup:</p><ul><li>An <strong>online ranking model</strong> serves as the reward model.<li>A <strong>reference model</strong> performs rollouts to generate multiple candidate samples.<li>The <strong>reward model</strong> scores these samples.<li>The <strong>policy model</strong> is then updated based on these scores.<li>The reference model is periodically synchronized with the policy model.</ul><p>This iterative RL loop progressively refines the model’s generation quality beyond what supervised training alone can achieve.</p><h2 id="sparse-attention-for-long-term-user-behavior-modeling"><span class="me-2">Sparse Attention for Long-Term User Behavior Modeling</span><a href="#sparse-attention-for-long-term-user-behavior-modeling" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><ul><li><a href="https://www.arxiv.org/pdf/2601.17836">Paper</a><li><a href="https://github.com/laiweijiang/SparseCTR">Code</a></ul><p>This paper from Meituan addresses long-sequence modeling for CTR prediction. Its central argument is that user behavior sequences fundamentally differ from natural language text—they exhibit strong <strong>personalization</strong> and <strong>temporal</strong> patterns that require specialized attention mechanisms.</p><p><a href="/assets/meituan-sparse.png" class="popup img-link shimmer"><img src="/assets/meituan-sparse.png" alt="Meituan Sparse Attention" loading="lazy"></a></p><h3 id="evolutionary-sparse-self-attention-for-personalization"><span class="me-2">Evolutionary Sparse Self-Attention for Personalization</span><a href="#evolutionary-sparse-self-attention-for-personalization" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>The proposed personalization mechanism consists of three attention types:</p><ol><li><p><strong>Temporal Chunking</strong>: The user’s long behavior sequence is chunked based on the time gap between adjacent actions, using top-k selection to determine chunk boundaries (with padding for uniformity). While the authors frame this as capturing personalized patterns, the chunking is purely temporal.</p><li><strong>Three-Level Attention</strong>:<ul><li><strong>Global Attention</strong>: Keys and values within each chunk are aggregated to form chunk-level representations, enabling attention across all chunks.<li><strong>Transitional Attention</strong>: The last few actions from each chunk are selected to capture cross-chunk transition patterns.<li><strong>Local Attention</strong>: A sliding window mechanism over the full sequence, with the user embedding prepended as the first token.</ul><li><strong>Gated Fusion</strong>: The outputs from all three attention types are combined via a learned gating mechanism.</ol><h3 id="temporal-encoding"><span class="me-2">Temporal Encoding</span><a href="#temporal-encoding" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>The temporal encoding is particularly well-designed with three components:</p><ul><li><strong>Time Delta Encoding</strong>: Time differences between actions are bucketized, and each attention head has a learnable parameter controlling its temporal sensitivity.<li><strong>Hour-of-Day Encoding</strong>: A sinusoidal encoding captures periodic daily patterns.<li><strong>Weekend Encoding</strong>: A binary signal (0 if both actions $(i)$ and $(j)$ fall on weekends, -1 otherwise) captures weekly periodicity.</ul><p>All temporal biases are summed and added to the scaled dot-product attention scores before softmax computation.</p><h3 id="prediction-and-results"><span class="me-2">Prediction and Results</span><a href="#prediction-and-results" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>For CTR prediction, the model extracts the last-layer representation corresponding to the candidate item’s position in the sequence, concatenates it with the user embedding, and feeds it through an MLP.</p><p>In their experiments, the proposed sparse attention mechanism outperforms alternatives such as NSAttention and DilatedAttention. They also compare different chunking strategies (e.g., similarity-based chunking) and find that their time-gap-based approach performs best.</p><h2 id="farewell-to-item-ids-bridging-generalization-and-memorization"><span class="me-2">Farewell to Item IDs: Bridging Generalization and Memorization</span><a href="#farewell-to-item-ids-bridging-generalization-and-memorization" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><ul><li><a href="https://arxiv.org/pdf/2601.22694">Paper</a></ul><p>This ByteDance paper tackles a fundamental tension in using semantic IDs for ranking models: <strong>semantic IDs excel at generalization but sacrifice memorization</strong>, leading to degraded performance when naively replacing traditional item IDs.</p><p><a href="/assets/bytedance-sid.png" class="popup img-link shimmer"><img src="/assets/bytedance-sid.png" alt="Bytedance SID" loading="lazy"></a></p><h3 id="collaborative-semantic-embedding-alignment"><span class="me-2">Collaborative-Semantic Embedding Alignment</span><a href="#collaborative-semantic-embedding-alignment" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>The embedding generation pipeline first aligns collaborative and semantic signals through <strong>contrastive learning</strong>, fusing both types of information into a unified representation. RQ-KMeans is then applied to generate the final semantic IDs.</p><h3 id="the-generalizationmemorization-trade-off"><span class="me-2">The Generalization–Memorization Trade-off</span><a href="#the-generalizationmemorization-trade-off" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>The paper explicitly acknowledges what many practitioners have observed: <strong>directly replacing item IDs with semantic IDs in ranking models hurts performance</strong>. The reason is that semantic IDs capture high-level semantic similarities but lose the fine-grained, instance-level memorization that traditional IDs provide.</p><p>Their solution is a <strong>dual-encoding</strong> approach:</p><ul><li><strong>Semantic IDs</strong> handle the <strong>generalization</strong> component (broad semantic understanding).<li><strong>Encoded IDs</strong> handle the <strong>memorization</strong> component (instance-level discrimination).</ul><p>These two representations are fed into separate branches of a Deep &amp; Wide architecture, combining the strengths of both.</p><h3 id="bpe-based-id-encoding-for-memorization"><span class="me-2">BPE-based ID Encoding for Memorization</span><a href="#bpe-based-id-encoding-for-memorization" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>The encoding for memorization is particularly creative: they train a <strong>Byte Pair Encoding (BPE)</strong> model on the semantic ID sequences to discover frequently co-occurring ID patterns. This is analogous to how BPE learns subword units in NLP: here it learns “sub-item” patterns that capture &amp; memorize collaborative structure.</p><h3 id="training-objective"><span class="me-2">Training Objective</span><a href="#training-objective" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>The final model is trained with both <strong>discriminative</strong> and <strong>next-token prediction (NTP)</strong> losses, consistent with the emerging standard in generative recommendation systems.</p><h2 id="key-takeaways"><span class="me-2">Key Takeaways</span><a href="#key-takeaways" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>These five papers highlight several trends in the generative recommendation space:</p><ol><li><p><strong>Feature interaction design matters</strong>: HyFormer demonstrates that carefully orchestrated cross-attention between sequential and non-sequential features yields significant improvements over naive approaches.</p><li><p><strong>Collaborative signals remain essential</strong>: Both Token-level Collaborative Alignment and Farewell to Item IDs show that collaborative filtering signals are complementary to semantic understanding—generative recommenders benefit from explicitly incorporating them.</p><li><p><strong>Semantic ID quality has diminishing returns</strong>: OneMall’s experiments suggest that while reducing ID conflicts is important, the marginal benefit decreases rapidly. The generalization–memorization balance (as explored in Farewell to Item IDs) may be a more impactful direction.</p><li><p><strong>Temporal-aware attention for user sequences</strong>: Meituan’s work reinforces that user behavior sequences require specialized treatment, particularly for temporal dynamics—that generic Transformer architectures do not natively provide.</p><li><p><strong>RL-based post-training is becoming standard</strong>: Both OneMall and the broader trend in the field confirm that RL-based refinement after supervised pre-training is increasingly the norm for generative recommenders.</p></ol><blockquote class="prompt-tip"><p>If you find this post helpful, feel free to scan the QR code below to support me and treat me to a cup of coffee</p></blockquote><p><a href="/assets/qr%20code.png" class="popup img-link shimmer"><img src="/assets/qr%20code.png" alt="Thank You" width="300" height="300" loading="lazy"></a></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw me-1"></i> <a href="/categories/machine-learning/">Machine Learning</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw me-1"></i> <a href="/tags/generative-recommender/" class="post-tag no-text-decoration" >generative-recommender</a> <a href="/tags/llm4rec/" class="post-tag no-text-decoration" >llm4rec</a> <a href="/tags/semantic-id/" class="post-tag no-text-decoration" >semantic-id</a> <a href="/tags/user-sequence-modeling/" class="post-tag no-text-decoration" >user-sequence-modeling</a> <a href="/tags/sparse-attention/" class="post-tag no-text-decoration" >sparse-attention</a> <a href="/tags/cross-attention/" class="post-tag no-text-decoration" >cross-attention</a></div><div class=" post-tail-bottom d-flex justify-content-between align-items-center mt-5 pb-2 " ><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper d-flex align-items-center"> <span class="share-label text-muted">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=A%20Random%20Walk%20Down%20Recsys%20-%20Part%202%20-%20Coding%20Monkey&url=https%3A%2F%2Fpyemma.github.io%2FA-Random-Walk-Down-Recsys-Part-2%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Twitter" aria-label="Twitter"> <i class="fa-fw fa-brands fa-square-x-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=A%20Random%20Walk%20Down%20Recsys%20-%20Part%202%20-%20Coding%20Monkey&u=https%3A%2F%2Fpyemma.github.io%2FA-Random-Walk-Down-Recsys-Part-2%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Facebook" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fpyemma.github.io%2FA-Random-Walk-Down-Recsys-Part-2%2F&text=A%20Random%20Walk%20Down%20Recsys%20-%20Part%202%20-%20Coding%20Monkey" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Telegram" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <button id="copy-link" aria-label="Copy link" class="btn small" data-bs-toggle="tooltip" data-bs-placement="top" title="Copy link" data-title-succeed="Link copied successfully!" > <i class="fa-fw fas fa-link pe-none fs-6"></i> </button> </span></div></div></div></article></main><aside aria-label="Panel" id="panel-wrapper" class="col-xl-3 ps-2 mb-5 text-muted"><div class="access"><section id="access-lastmod"><h2 class="panel-heading">Recently Updated</h2><ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2"><li class="text-truncate lh-lg"> <a href="/A-Random-Walk-Down-Recsys-Part-3/">A Random Walk Down Recsys - Part 3</a><li class="text-truncate lh-lg"> <a href="/A-Random-Walk-Down-Recsys-Part-2/">A Random Walk Down Recsys - Part 2</a><li class="text-truncate lh-lg"> <a href="/OpenOneRec-RL/">Learning VERL Part 1 - A Perspective from OpenOneRec</a><li class="text-truncate lh-lg"> <a href="/Recommendation-Paper-2025-Review/">My 2025 Recommendation System Paper Summary</a><li class="text-truncate lh-lg"> <a href="/FSDP2-Code-Walk/">FSDP2 Under the Hood - A Deep Dive into PyTorch's Fully Sharded Data Parallel Implementation</a></ul></section><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/llm4rec/">llm4rec</a> <a class="post-tag btn btn-outline-primary" href="/tags/user-sequence-modeling/">user-sequence-modeling</a> <a class="post-tag btn btn-outline-primary" href="/tags/machine-learning-design/">machine learning design</a> <a class="post-tag btn btn-outline-primary" href="/tags/recommendation-system/">recommendation-system</a> <a class="post-tag btn btn-outline-primary" href="/tags/system-design/">system design</a> <a class="post-tag btn btn-outline-primary" href="/tags/generative-recommender/">generative-recommender</a> <a class="post-tag btn btn-outline-primary" href="/tags/semantic-id/">semantic-id</a> <a class="post-tag btn btn-outline-primary" href="/tags/distributed-system/">distributed system</a> <a class="post-tag btn btn-outline-primary" href="/tags/distributed-training/">distributed-training</a> <a class="post-tag btn btn-outline-primary" href="/tags/embeddings/">embeddings</a></div></section></div><section id="toc-wrapper" class="d-none ps-0 pe-4"><h2 class="panel-heading ps-3 mb-2">Contents</h2><nav id="toc"></nav></section></aside></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4"><aside id="related-posts" aria-labelledby="related-label"><h3 class="mb-4" id="related-label">Further Reading</h3><nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4"><article class="col"> <a href="/A-Random-Walk-Down-Recsys/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1768723200" data-df="ll" > Jan 18, 2026 </time><h4 class="pt-0 my-2">A Random Walk Down Recsys - Part 1</h4><div class="text-muted"><p>This is a new series of blog beyond my conference paper reading blog, in which I would summarize the paper that I found interesting form Arxiv IR section and share my learnings. In this first blog...</p></div></div></a></article><article class="col"> <a href="/A-Random-Walk-Down-Recsys-Part-3/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1771747200" data-df="ll" > Feb 22, 2026 </time><h4 class="pt-0 my-2">A Random Walk Down Recsys - Part 3</h4><div class="text-muted"><p>Welcome back to the third installment of A Random Walk Down Recsys. This time, all five papers revolve around a single theme: Semantic IDs (SIDs) — how to generate them, how to improve their qualit...</p></div></div></a></article><article class="col"> <a href="/Recsys-2025-Paper-Summary/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1764230400" data-df="ll" > Nov 27, 2025 </time><h4 class="pt-0 my-2">Recsys 2025 Paper Summary</h4><div class="text-muted"><p>In this post, I would like to summary the paper from Recsys 2025 and share some of my learnings. We would cover several topics such as sequence modeling, cross domain learning as well as LLM integr...</p></div></div></a></article></nav></aside><nav class="post-navigation d-flex justify-content-between" aria-label="Post Navigation"> <a href="/OpenOneRec-RL/" class="btn btn-outline-primary" aria-label="Older" ><p>Learning VERL Part 1 - A Perspective from OpenOneRec</p></a> <a href="/A-Random-Walk-Down-Recsys-Part-3/" class="btn btn-outline-primary" aria-label="Newer" ><p>A Random Walk Down Recsys - Part 3</p></a></nav><div id="disqus_thread"><p class="text-center text-muted small">Comments powered by <a href="https://disqus.com/">Disqus</a>.</p></div><script type="text/javascript"> var disqus_config = function () { this.page.url = 'https://pyemma.github.io/A-Random-Walk-Down-Recsys-Part-2/'; this.page.identifier = '/A-Random-Walk-Down-Recsys-Part-2/'; };var disqus_observer = new IntersectionObserver( function (entries) { if (entries[0].isIntersecting) { (function () { var d = document, s = d.createElement('script'); s.src = 'https://pyemma.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); disqus_observer.disconnect(); } }, { threshold: [0] } ); disqus_observer.observe(document.getElementById('disqus_thread'));function reloadDisqus() { if (event.source === window && event.data && event.data.direction === ModeToggle.ID) {if (typeof DISQUS === 'undefined') { return; } if (document.readyState == 'complete') { DISQUS.reset({ reload: true, config: disqus_config }); } } } if (document.getElementById('mode-toggle')) { window.addEventListener('message', reloadDisqus); } </script><footer aria-label="Site Info" class=" d-flex flex-column justify-content-center text-muted flex-lg-row justify-content-lg-between align-items-lg-center pb-lg-3 " ><p>© <time>2026</time> <a href="https://github.com/pyemma">Coding Monkey</a>. <span data-bs-toggle="tooltip" data-bs-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author." >Some rights reserved.</span></p><p>Using the <a data-bs-toggle="tooltip" data-bs-placement="top" title="v7.1.1" href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener" >Chirpy</a> theme for <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>.</p></footer></div></div><div id="search-result-wrapper" class="d-flex justify-content-center d-none"><div class="col-11 content"><div id="search-hints"><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/llm4rec/">llm4rec</a> <a class="post-tag btn btn-outline-primary" href="/tags/user-sequence-modeling/">user-sequence-modeling</a> <a class="post-tag btn btn-outline-primary" href="/tags/machine-learning-design/">machine learning design</a> <a class="post-tag btn btn-outline-primary" href="/tags/recommendation-system/">recommendation-system</a> <a class="post-tag btn btn-outline-primary" href="/tags/system-design/">system design</a> <a class="post-tag btn btn-outline-primary" href="/tags/generative-recommender/">generative-recommender</a> <a class="post-tag btn btn-outline-primary" href="/tags/semantic-id/">semantic-id</a> <a class="post-tag btn btn-outline-primary" href="/tags/distributed-system/">distributed system</a> <a class="post-tag btn btn-outline-primary" href="/tags/distributed-training/">distributed-training</a> <a class="post-tag btn btn-outline-primary" href="/tags/embeddings/">embeddings</a></div></section></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><aside aria-label="Scroll to Top"> <button id="back-to-top" type="button" class="btn btn-lg btn-box-shadow"> <i class="fas fa-angle-up"></i> </button></aside></div><div id="mask"></div><aside id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-bs-animation="true" data-bs-autohide="false" ><div class="toast-header"> <button type="button" class="btn-close ms-auto" data-bs-dismiss="toast" aria-label="Close" ></button></div><div class="toast-body text-center pt-0"><p class="px-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></aside><script src="https://cdn.jsdelivr.net/combine/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.umd.min.js,npm/glightbox@3.3.0/dist/js/glightbox.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.13/dayjs.min.js,npm/dayjs@1.11.13/locale/en.js,npm/dayjs@1.11.13/plugin/relativeTime.js,npm/dayjs@1.11.13/plugin/localizedFormat.js,npm/tocbot@4.29.0/dist/tocbot.min.js"></script> <script src="/assets/js/dist/post.min.js"></script> <script src="/assets/js/data/mathjax.js"></script> <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml.js"></script> <script defer src="/app.min.js?baseurl=&register=true" ></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-M1GM2SJR6M"></script> <script> document.addEventListener('DOMContentLoaded', function (event) { window.dataLayer = window.dataLayer || []; function gtag() { dataLayer.push(arguments); } gtag('js', new Date()); gtag('config', 'G-M1GM2SJR6M'); }); </script> <script>SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<article class="px-1 px-sm-2 px-lg-4 px-xl-0"><header><h2><a href="{url}">{title}</a></h2><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div></header><p>{snippet}</p></article>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
