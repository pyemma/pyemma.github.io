<feed xmlns="http://www.w3.org/2005/Atom"> <id>https://pyemma.github.io/</id><title>Coding Monkey</title><subtitle>I am a coding monkey, and I am proud of it. I have done lots of work in machine learning area, especially recommendation system and AutoML. This blog summarize my journey to become an expert monkey in distributed system and LLM.</subtitle> <updated>2025-11-29T11:22:52-08:00</updated> <author> <name>Coding Monkey</name> <uri>https://pyemma.github.io/</uri> </author><link rel="self" type="application/atom+xml" href="https://pyemma.github.io/feed.xml"/><link rel="alternate" type="text/html" hreflang="en" href="https://pyemma.github.io/"/> <generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator> <rights> © 2025 Coding Monkey </rights> <icon>/assets/img/favicons/favicon.ico</icon> <logo>/assets/img/favicons/favicon-96x96.png</logo> <entry><title>Recsys 2025 Paper Summary</title><link href="https://pyemma.github.io/Recsys-2025-Paper-Summary/" rel="alternate" type="text/html" title="Recsys 2025 Paper Summary" /><published>2025-11-27T00:00:00-08:00</published> <updated>2025-11-27T00:00:00-08:00</updated> <id>https://pyemma.github.io/Recsys-2025-Paper-Summary/</id> <content src="https://pyemma.github.io/Recsys-2025-Paper-Summary/" /> <author> <name>pyemma</name> </author> <category term="Machine Learning" /> <summary>In this post, I would like to summary the paper from Recsys 2025 and share some of my learnings. We would cover several topics such as sequence modeling, cross domain learning as well as LLM integration with recommendation system. Here is a full list of papers in this post: Beyond Immediate Click: Engagement-Aware and MoE-Enhanced Transformers for Sequential Movie Recommendation LEAF: Lig...</summary> </entry> <entry><title>KDD 2025 Paper Summary</title><link href="https://pyemma.github.io/KDD-2025-Paper-Summary/" rel="alternate" type="text/html" title="KDD 2025 Paper Summary" /><published>2025-10-17T00:00:00-07:00</published> <updated>2025-10-17T00:00:00-07:00</updated> <id>https://pyemma.github.io/KDD-2025-Paper-Summary/</id> <content src="https://pyemma.github.io/KDD-2025-Paper-Summary/" /> <author> <name>pyemma</name> </author> <category term="Machine Learning" /> <summary>It has been a while since KDD 2025, finally I have had sometime to finish reading all papers that I interested in and summarize some of my learnings in this post :sweat_smile:. My primary focus is still on the work related to recommendation system from industry track, especially the area of user sequence modeling and the integration of LLM in recsys. Below if the follow list of papers covered i...</summary> </entry> <entry><title>PyTorch 性能与显存优化手册</title><link href="https://pyemma.github.io/Book-PyTorch-Training-Optimization/" rel="alternate" type="text/html" title="PyTorch 性能与显存优化手册" /><published>2025-07-20T00:00:00-07:00</published> <updated>2025-07-20T00:00:00-07:00</updated> <id>https://pyemma.github.io/Book-PyTorch-Training-Optimization/</id> <content src="https://pyemma.github.io/Book-PyTorch-Training-Optimization/" /> <author> <name>pyemma</name> </author> <category term="Distributed Training" /> <summary>前一阵子在得道 APP 上读完了这本《PyTorch 性能与显存优化手册》，感觉是一本很不错的 PyTorch Training 入门读物，很适合刚刚接触这个领域的新手小白来读；同时整本书也提供了一个 PyTorch Training 的优化大纲，可以作为一个引子来扩展去学习更加底层的知识和技术。 这篇帖子主要是我读的时候标记下来的一些知识点，并没有包含书籍里面的全部内容。强烈推荐大家去阅读原书，会非常有收获！ 基础性概念 在实际的应用中，我们一般会先优化显存然后再优化训练速度 在数据加载的过程中，可以通过将加载任务和模型计算容易进行重叠来进行优化，比如预加载技术；数据预处理也可以采用离线预处理技术或者优化 CPU 预处理代码的效率 随机读写模式的效率以硬盘的 IOPS 来衡量；而连续读写模式则是以 MB/s 来进行衡量 在 GPU 中，张量计算核心，标量计算...</summary> </entry> <entry><title>Recommendation System - Long User Sequence Modeling</title><link href="https://pyemma.github.io/Long-User-Sequence-Modeling-In-Recsys/" rel="alternate" type="text/html" title="Recommendation System - Long User Sequence Modeling" /><published>2025-06-28T00:00:00-07:00</published> <updated>2025-06-28T00:00:00-07:00</updated> <id>https://pyemma.github.io/Long-User-Sequence-Modeling-In-Recsys/</id> <content src="https://pyemma.github.io/Long-User-Sequence-Modeling-In-Recsys/" /> <author> <name>pyemma</name> </author> <category term="Machine Learning" /> <summary>User sequence modeling has been a hot topic recently in recommendation system thanks to the advancement of transformer architecture and more powerful hardware. In this blog, I would like to have a simple review on the evolution of user sequence modeling work, especially long user sequence modeling. Hope this blog could inspire broader exploration ideas for the future. Here is a quick outlets o...</summary> </entry> <entry><title>Recsys Paper Summary 2025 Q1</title><link href="https://pyemma.github.io/Recsys-Paper-Review-2025-Q1/" rel="alternate" type="text/html" title="Recsys Paper Summary 2025 Q1" /><published>2025-04-19T00:00:00-07:00</published> <updated>2025-04-19T00:00:00-07:00</updated> <id>https://pyemma.github.io/Recsys-Paper-Review-2025-Q1/</id> <content src="https://pyemma.github.io/Recsys-Paper-Review-2025-Q1/" /> <author> <name>pyemma</name> </author> <category term="Machine Learning" /> <summary>In this post, I would like to provide a simple summary on the papers I have read in the first quarter of 2025 and discuss some of my thoughts on recent trend regarding recommendation system. Here is the full list of papers in this summary, which are all available on Arxiv: Full-Stack Optimized Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation NoteLLM-2...</summary> </entry> </feed>
