<feed xmlns="http://www.w3.org/2005/Atom"> <id>https://pyemma.github.io/</id><title>Coding Monkey</title><subtitle>I am a coding monkey, and I am proud of it. I have done lots of work in machine learning area, especially recommendation system and AutoML. This blog summarize my journey to become an expert monkey in distributed system and LLM.</subtitle> <updated>2026-01-18T16:11:18-08:00</updated> <author> <name>Coding Monkey</name> <uri>https://pyemma.github.io/</uri> </author><link rel="self" type="application/atom+xml" href="https://pyemma.github.io/feed.xml"/><link rel="alternate" type="text/html" hreflang="en" href="https://pyemma.github.io/"/> <generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator> <rights> © 2026 Coding Monkey </rights> <icon>/assets/img/favicons/favicon.ico</icon> <logo>/assets/img/favicons/favicon-96x96.png</logo> <entry><title>A Random Walk Down Recsys - Part 1</title><link href="https://pyemma.github.io/A-Random-Walk-Down-Recsys/" rel="alternate" type="text/html" title="A Random Walk Down Recsys - Part 1" /><published>2026-01-18T00:00:00-08:00</published> <updated>2026-01-18T00:00:00-08:00</updated> <id>https://pyemma.github.io/A-Random-Walk-Down-Recsys/</id> <content src="https://pyemma.github.io/A-Random-Walk-Down-Recsys/" /> <author> <name>pyemma</name> </author> <category term="Machine Learning" /> <summary>This is a new series of blog beyond my conference paper reading blog, in which I would summarize the paper that I found interesting form Arxiv IR section and share my learnings. In this first blog, I would like to summarize key insights from four papers that represent the current state-of-the-art in generative recommendation: OpenOneRec, OxygenRec, Meta’s Efficient Sequential Recommendation, a...</summary> </entry> <entry><title>FSDP2 Under the Hood - A Deep Dive into PyTorch's Fully Sharded Data Parallel Implementation</title><link href="https://pyemma.github.io/FSDP2-Code-Walk/" rel="alternate" type="text/html" title="FSDP2 Under the Hood - A Deep Dive into PyTorch&amp;apos;s Fully Sharded Data Parallel Implementation" /><published>2026-01-03T00:00:00-08:00</published> <updated>2026-01-03T00:00:00-08:00</updated> <id>https://pyemma.github.io/FSDP2-Code-Walk/</id> <content src="https://pyemma.github.io/FSDP2-Code-Walk/" /> <author> <name>pyemma</name> </author> <category term="Distributed Training" /> <summary>Fully Sharded Data Parallel (FSDP) is PyTorch’s approach to training large models that don’t fit in a single GPU’s memory. FSDP2 represents a significant redesign from FSDP1, with improved performance, better composability, and a cleaner architecture built on top of PyTorch’s DTensor abstraction. In this post, I’ll walk through the implementation details of FSDP2, exploring how it shards parame...</summary> </entry> <entry><title>My 2025 Recommendation System Paper Summary</title><link href="https://pyemma.github.io/Recommendation-Paper-2025-Review/" rel="alternate" type="text/html" title="My 2025 Recommendation System Paper Summary" /><published>2026-01-02T00:00:00-08:00</published> <updated>2026-01-02T00:00:00-08:00</updated> <id>https://pyemma.github.io/Recommendation-Paper-2025-Review/</id> <content src="https://pyemma.github.io/Recommendation-Paper-2025-Review/" /> <author> <name>pyemma</name> </author> <category term="Machine Learning" /> <summary>In this post, I would like to share some insights from the paper I have read in year 2025 and summarize some trends over the year. The One The best work I enjoyed this year is the One-series from Kuaishou, such as OneRec, OneSearch, OneRec v2, etc. From high level, the One-series use a single generative recommendation model (which is usually use encoder-decoder or some variation as the backbo...</summary> </entry> <entry><title>Recsys 2025 Paper Summary</title><link href="https://pyemma.github.io/Recsys-2025-Paper-Summary/" rel="alternate" type="text/html" title="Recsys 2025 Paper Summary" /><published>2025-11-27T00:00:00-08:00</published> <updated>2025-11-27T00:00:00-08:00</updated> <id>https://pyemma.github.io/Recsys-2025-Paper-Summary/</id> <content src="https://pyemma.github.io/Recsys-2025-Paper-Summary/" /> <author> <name>pyemma</name> </author> <category term="Machine Learning" /> <summary>In this post, I would like to summary the paper from Recsys 2025 and share some of my learnings. We would cover several topics such as sequence modeling, cross domain learning as well as LLM integration with recommendation system. Here is a full list of papers in this post: Beyond Immediate Click: Engagement-Aware and MoE-Enhanced Transformers for Sequential Movie Recommendation LEAF: Lig...</summary> </entry> <entry><title>KDD 2025 Paper Summary</title><link href="https://pyemma.github.io/KDD-2025-Paper-Summary/" rel="alternate" type="text/html" title="KDD 2025 Paper Summary" /><published>2025-10-17T00:00:00-07:00</published> <updated>2025-10-17T00:00:00-07:00</updated> <id>https://pyemma.github.io/KDD-2025-Paper-Summary/</id> <content src="https://pyemma.github.io/KDD-2025-Paper-Summary/" /> <author> <name>pyemma</name> </author> <category term="Machine Learning" /> <summary>It has been a while since KDD 2025, finally I have had sometime to finish reading all papers that I interested in and summarize some of my learnings in this post :sweat_smile:. My primary focus is still on the work related to recommendation system from industry track, especially the area of user sequence modeling and the integration of LLM in recsys. Below if the follow list of papers covered i...</summary> </entry> </feed>
